{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37778ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49b9d813",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Titles  Scores\n",
      "0   Fallen Edmonton police officers were ambushed,... -0.5719\n",
      "1   Foreign interference is the 'greatest strategi...  0.4939\n",
      "2   'We were shocked': Int'l med students who fled... -0.2732\n",
      "3   Fairleigh Dickinson shocks Purdue to become se...  0.0000\n",
      "4   Actor Lance Reddick, known for The Wire and Jo... -0.6486\n",
      "5   2 Edmonton police officers were ambushed, shot... -0.2960\n",
      "6   The International Criminal Court wants Vladimi... -0.7579\n",
      "7                                        The National  0.0000\n",
      "8   Teen signs one-day contract with Pittsburgh Pe...  0.0000\n",
      "9   Parents speak out after son, 5, overdoses due ... -0.4019\n",
      "10                Canadian 'super pigs' are a problem  0.2960\n",
      "11  MP's questioning of UWindsor law prof during f... -0.6597\n",
      "12              Watch CBC News Explore free streaming  0.5106\n",
      "13  Marketplace: Retail Tricks â€” putting jeans siz... -0.1280\n",
      "14  Push: Welcome to the world of the 'Wheelie Peeps'  0.4588\n",
      "15  A man in his 30s returned to his old high scho... -0.2960\n",
      "16                              History of the Sitcom  0.0000\n"
     ]
    }
   ],
   "source": [
    "#get data from CBC\n",
    "url_cbc = \"https://www.cbc.ca/\"\n",
    "response = requests.get(url_cbc)\n",
    "\n",
    "soup = bs(response.content, 'html.parser')\n",
    "\n",
    "corpus_CBC = []\n",
    "for article in soup.find_all('div', class_='contentWrapper'):\n",
    "    title = article.find('h3', class_='headline').text.strip()\n",
    "    corpus_CBC += [title]\n",
    "\n",
    "\n",
    "#find sentiment scores built-in analyzer in NLTK's Vader Module\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "scores = [sia.polarity_scores(title)['compound'] for title in corpus_CBC]\n",
    "df = pd.DataFrame({'Titles': corpus_CBC, 'Scores': scores})\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5f11758",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get data from movie review corpus\n",
    "file_path = \"./mix20_rand700_tokens_cleaned/tokens/\"\n",
    "neg_files = os.listdir(file_path + \"neg\") #negative\n",
    "pos_files = os.listdir(file_path + \"pos\") #positive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "948a33e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_files(file_set, path):\n",
    "    tokenized_data = []\n",
    "    for file in file_set:\n",
    "        with open(path + file, 'r' ,encoding='utf-8', errors='ignore') as f:\n",
    "            content = f.read()\n",
    "            # tokenize the data\n",
    "            tokens = nltk.sent_tokenize(content)\n",
    "            tokenized_data += tokens\n",
    "    return tokenized_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87045e62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neg_data = tokenize_files(neg_files, file_path+\"neg/\")\n",
    "pos_data = tokenize_files(pos_files, file_path+\"pos/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a357fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 69.88380736277924%\n"
     ]
    }
   ],
   "source": [
    "scores_pos = [sia.polarity_scores(sentence)['compound'] for sentence in pos_data]\n",
    "scores_neg = [sia.polarity_scores(sentence)['compound'] for sentence in neg_data]\n",
    "\n",
    "# We assume that all the sentences in the positive review are positive, and vice versa\n",
    "false_result = 0\n",
    "for score in scores_neg:\n",
    "    if score > 0:\n",
    "        false_result += 1\n",
    "for score in scores_pos:\n",
    "    if score < 0:\n",
    "        false_result += 1  \n",
    "        \n",
    "accuracy = 1 - (false_result / len(scores_neg+scores_pos))\n",
    "print(\"Accuracy is {}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5461575b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score for positive data is: 0.10574544504643899\n",
      "Average score for negative data is: 0.01536359860770514\n"
     ]
    }
   ],
   "source": [
    "average_score_pos = sum(scores_pos) / len(scores_pos)\n",
    "average_score_neg = sum(scores_neg) / len(scores_neg)\n",
    "print('Average score for positive data is:', average_score_pos)\n",
    "print('Average score for negative data is:', average_score_neg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
